/**
 * â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
 * HIVE BLOCKCHAIN LOOKUP MODULE
 * â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
 * Shared utilities for searching and verifying content on Hive blockchain
 * Used by: hash-explorer.html, index.html (smart archive flow)
 * 
 * Key Features:
 * - 9-node failover system for maximum reliability
 * - Smart 5-tag system for fast lookups (~1,900x improvement)
 * - Content hash generation (SHA-256, BLAKE2b, MD5)
 * - Hash comparison for integrity verification
 * 
 * Dependencies:
 * - blakejs (for BLAKE2b hashing)
 * - md5.js (for MD5 hashing)
 * - Web Crypto API (for SHA-256)
 * 
 * @version 1.0.0
 * @date 2024-11-13
 * â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
 */

// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
// DEBUG MODE CONFIGURATION
// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

const HIVE_LOOKUP_DEBUG = false;
const hiveDebugLog = (...args) => { if (HIVE_LOOKUP_DEBUG) console.log(...args); };
const hiveDebugWarn = (...args) => { if (HIVE_LOOKUP_DEBUG) console.warn(...args); };

// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
// HIVE API CONFIGURATION
// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

/**
 * Multi-Node Failover Configuration
 * Uses 9 independent Hive API nodes for maximum reliability
 * Automatically tries next node if one fails
 */
const HIVE_API_NODES = [
    'https://api.hive.blog',
    'https://api.openhive.network',
    'https://hive-api.arcange.eu',
    'https://rpc.ausbit.dev',
    'https://api.hivekings.com',
    'https://anyx.io',
    'https://rpc.ecency.com',
    'https://api.deathwing.me',
    'https://hive.roelandp.nl'
];

/**
 * Global search state management
 * Tracks active search to prevent concurrency bugs and memory leaks
 */
let currentSearchId = 0;
let currentSearchController = null;
let activeSearchId = null;

/**
 * Cancel the current Hive search in progress
 */
function cancelCurrentSearch() {
    if (currentSearchController) {
        hiveDebugLog('ğŸ›‘ User cancelled search');
        currentSearchController.abort();
        // Don't null here - let fetchHiveAPIWithFailover's finally block clean it up
    }
}

// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
// HIVE API COMMUNICATION
// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

/**
 * Fetch with automatic failover and exponential backoff
 * Tries multiple nodes with retry logic for maximum reliability
 * 
 * @param {Object} params - Hive API request parameters
 * @param {number} maxRetries - Maximum retries per node (default: 2)
 * @param {Function} progressCallback - Optional callback for progress updates: (nodeIndex, totalNodes, nodeName, retry) => void
 * @returns {Promise<Array>} - Array of Hive posts
 * @throws {Error} - If all nodes fail or search is cancelled
 */
async function fetchHiveAPIWithFailover(params, maxRetries = 2, progressCallback = null) {
    const errors = [];
    
    // Assign unique ID to this search (prevents concurrency bugs)
    currentSearchId++;
    const thisSearchId = currentSearchId;
    
    // Check if another search is already in progress
    if (activeSearchId !== null && currentSearchController && !currentSearchController.signal.aborted) {
        hiveDebugWarn('âš ï¸  Search already in progress - rejecting concurrent request');
        throw new Error('A search is already in progress. Please wait for it to complete or cancel it first.');
    }
    
    // Create controller for this specific search
    const thisSearchController = new AbortController();
    
    // Mark this search as active
    activeSearchId = thisSearchId;
    currentSearchController = thisSearchController;
    
    try {
        for (let nodeIndex = 0; nodeIndex < HIVE_API_NODES.length; nodeIndex++) {
            const apiUrl = HIVE_API_NODES[nodeIndex];
            
            // Try each node with exponential backoff retries
            for (let retry = 0; retry <= maxRetries; retry++) {
                // Create a controller for this specific request (combines timeout + user cancel)
                const requestController = new AbortController();
                const timeoutId = setTimeout(() => requestController.abort(), 5000); // 5-second timeout
                
                // Link user cancellation to this request
                if (thisSearchController.signal.aborted) {
                    clearTimeout(timeoutId);
                    throw new Error('Search cancelled by user');
                }
                
                const cancelListener = () => requestController.abort();
                thisSearchController.signal.addEventListener('abort', cancelListener);
                
                try {
                    const startTime = Date.now();
                    hiveDebugLog(`ğŸ”Œ [${nodeIndex + 1}/${HIVE_API_NODES.length}] Trying ${apiUrl}${retry > 0 ? ` (retry ${retry})` : ''}...`);
                    
                    // Notify UI of progress
                    if (progressCallback) {
                        const nodeName = apiUrl.replace('https://', '').split('/')[0];
                        progressCallback(nodeIndex + 1, HIVE_API_NODES.length, nodeName, retry);
                    }
                    
                    const response = await fetch(apiUrl, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(params),
                        signal: requestController.signal
                    });
                    
                    clearTimeout(timeoutId); // Clear timeout on success
                    thisSearchController.signal.removeEventListener('abort', cancelListener);
                    
                    if (!response.ok) {
                        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
                    }
                    
                    const data = await response.json();
                    const duration = Date.now() - startTime;
                    
                    if (data.error) {
                        throw new Error(`Hive API error: ${data.error.message || JSON.stringify(data.error)}`);
                    }
                    
                    if (!data.result) {
                        throw new Error('Invalid response: missing result field');
                    }
                    
                    // Security: Validate response structure and enforce size limits
                    // Accept both arrays (bridge.get_ranked_posts) and objects (bridge.get_discussion)
                    const isArray = Array.isArray(data.result);
                    const isObject = typeof data.result === 'object' && data.result !== null && !isArray;
                    
                    if (!isArray && !isObject) {
                        throw new Error(`Invalid response: result is ${typeof data.result}, expected array or object`);
                    }
                    
                    // Prevent DoS from malicious nodes sending huge payloads
                    const MAX_ITEMS = 1000; // Reasonable limit for API responses
                    
                    if (isArray) {
                        if (data.result.length > MAX_ITEMS) {
                            console.warn(`âš ï¸  Response truncated: ${data.result.length} posts â†’ ${MAX_ITEMS} posts`);
                            data.result = data.result.slice(0, MAX_ITEMS);
                        }
                        hiveDebugLog(`âœ… Success from ${apiUrl} (${duration}ms, ${data.result.length} posts)`);
                    } else if (isObject) {
                        const itemCount = Object.keys(data.result).length;
                        if (itemCount > MAX_ITEMS) {
                            console.warn(`âš ï¸  Response truncated: ${itemCount} items â†’ ${MAX_ITEMS} items`);
                            const keys = Object.keys(data.result).slice(0, MAX_ITEMS);
                            const truncated = {};
                            keys.forEach(key => truncated[key] = data.result[key]);
                            data.result = truncated;
                        }
                        hiveDebugLog(`âœ… Success from ${apiUrl} (${duration}ms, ${itemCount} items)`);
                    }
                    
                    return data.result;
                    
                } catch (error) {
                    clearTimeout(timeoutId); // Always clear timeout on error
                    thisSearchController.signal.removeEventListener('abort', cancelListener);
                    
                    // Check if this was a user cancellation
                    if (thisSearchController.signal.aborted) {
                        throw new Error('Search cancelled by user');
                    }
                    
                    const errorMsg = `${apiUrl}: ${error.message}`;
                    errors.push(errorMsg);
                    console.warn(`âš ï¸  Attempt failed: ${errorMsg}`);
                    
                    // Exponential backoff: wait before retry (100ms, 200ms, 400ms...)
                    if (retry < maxRetries) {
                        const delay = Math.min(100 * Math.pow(2, retry), 1000);
                        hiveDebugLog(`   â±ï¸  Waiting ${delay}ms before retry...`);
                        await new Promise(resolve => setTimeout(resolve, delay));
                    }
                }
            }
        }
        
        // All nodes exhausted
        console.error('âŒ All Hive API nodes failed after retries!');
        console.error('   Errors:', errors);
        throw new Error(`All ${HIVE_API_NODES.length} Hive nodes failed. Please check your internet connection or try again later.`);
        
    } finally {
        // Clean up global state only if this search is still the active one
        // (prevents race condition where old search clears new search's controller)
        if (activeSearchId === thisSearchId) {
            activeSearchId = null;
            currentSearchController = null;
        }
    }
}

/**
 * Search Hive blockchain by tags with pagination
 * Uses primary tag + filters for exact matches on all tags
 * Paginates through multiple pages to find older archives
 * 
 * @param {Array<string>} tags - Array of tags to search (first tag is primary)
 * @param {Function} progressCallback - Optional callback for progress updates: (nodeIndex, totalNodes, nodeName, retry) => void
 * @param {number} maxPages - Maximum pages to fetch (default: 5 = 100 posts max)
 * @returns {Promise<Array>} - Array of matching Hive posts
 */
async function searchHiveByTags(tags, progressCallback = null, maxPages = 5) {
    hiveDebugLog('ğŸ“¡ Searching Hive with tags:', tags);
    
    // CRITICAL: Hive API searches by PRIMARY tag (first tag in post's tag list)
    // ALL archives use "archivedcontenthaf" as the primary tag (position 0)
    const primaryTag = 'archivedcontenthaf';
    
    const allPosts = [];
    let startAuthor = null;
    let startPermlink = null;
    
    try {
        for (let page = 0; page < maxPages; page++) {
            const params = {
                jsonrpc: '2.0',
                method: 'bridge.get_ranked_posts',
                params: {
                    sort: 'created',
                    tag: primaryTag,
                    observer: '',
                    limit: 20  // Hive API max is 20
                },
                id: 1
            };
            
            // Add pagination parameters for subsequent pages
            if (startAuthor && startPermlink) {
                params.params.start_author = startAuthor;
                params.params.start_permlink = startPermlink;
            }
            
            hiveDebugLog(`ğŸ” Fetching page ${page + 1}/${maxPages}...`);
            
            const posts = await fetchHiveAPIWithFailover(params, 2, progressCallback);
            
            if (posts.length === 0) {
                hiveDebugLog(`ğŸ“­ No more posts found at page ${page + 1}`);
                break;
            }
            
            // Skip the first post on subsequent pages (it's the last post from previous page)
            const newPosts = page === 0 ? posts : posts.slice(1);
            
            if (newPosts.length === 0) {
                hiveDebugLog(`ğŸ“­ No new posts on page ${page + 1}`);
                break;
            }
            
            allPosts.push(...newPosts);
            hiveDebugLog(`âœ… Page ${page + 1}: Found ${newPosts.length} posts (total: ${allPosts.length})`);
            
            // Set pagination cursor for next page
            const lastPost = posts[posts.length - 1];
            startAuthor = lastPost.author;
            startPermlink = lastPost.permlink;
            
            // If we got fewer than 20 posts, we've reached the end
            if (posts.length < 20) {
                hiveDebugLog(`ğŸ“­ Reached end of archives at page ${page + 1}`);
                break;
            }
        }
        
        hiveDebugLog(`âœ… Found ${allPosts.length} total posts with primary tag: ${primaryTag}`);
        
        // If we have smart tags (5 tags), filter to match all of them
        const filtered = allPosts.filter(post => {
            // Parse json_metadata if it's a string (Hive API returns it as string)
            let metadata = post.json_metadata;
            if (typeof metadata === 'string') {
                try {
                    metadata = JSON.parse(metadata);
                } catch (e) {
                    hiveDebugWarn('âš ï¸  Failed to parse json_metadata for post:', post.post_id);
                    return false;
                }
            }
            const postTags = (metadata?.tags || []).map(t => t.toLowerCase());
            return tags.every(tag => postTags.includes(tag.toLowerCase()));
        });
        
        hiveDebugLog(`âœ… After tag filtering: ${filtered.length} posts`);
        return filtered;
        
    } catch (error) {
        console.error('âŒ Search failed:', error.message);
        throw error;
    }
}

// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
// CONTENT EXTRACTION & HASHING
// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

/**
 * Generate cryptographic hashes for content verification
 * Creates SHA-256, BLAKE2b, and MD5 hashes
 * 
 * @param {string} content - Content to hash
 * @param {string} title - Title to hash (optional)
 * @returns {Promise<Object>} - Object with sha256, blake2b, and md5 hashes
 */
async function generateContentHash(content, title = '') {
    if (!content || typeof content !== 'string') {
        throw new Error('Invalid content for hashing: content must be a non-empty string');
    }
    
    const encoder = new TextEncoder();
    const data = encoder.encode(content);
    
    // SHA-256
    const sha256Buffer = await crypto.subtle.digest('SHA-256', data);
    const sha256 = Array.from(new Uint8Array(sha256Buffer))
        .map(b => b.toString(16).padStart(2, '0'))
        .join('');
    
    // BLAKE2b (convert string to Uint8Array first - blakejs requires bytes)
    const contentBytes = encoder.encode(content);
    const blake2b = blakejs.blake2bHex(contentBytes, null, 32);
    
    // MD5
    const md5Hash = md5(content);
    
    return { sha256, blake2b, md5: md5Hash };
}

/**
 * Extract content from HTML using Readability
 * Falls back to body.textContent if Readability unavailable
 * 
 * @param {string} html - HTML string to extract content from
 * @returns {Promise<string>} - Extracted text content
 */
async function extractContentFromHTML(html) {
    const parser = new DOMParser();
    const doc = parser.parseFromString(html, 'text/html');
    
    // Use Readability if available
    if (typeof Readability !== 'undefined') {
        const reader = new Readability(doc);
        const article = reader.parse();
        return article ? article.textContent : doc.body.textContent;
    }
    
    // Fallback: use body text
    return doc.body.textContent || '';
}

/**
 * Count words in text
 * 
 * @param {string} text - Text to count words in
 * @returns {number} - Word count
 */
function countWords(text) {
    return text.trim().split(/\s+/).filter(word => word.length > 0).length;
}

/**
 * Extract publication date metadata from HTML
 * Checks JSON-LD, meta tags, and time elements
 * 
 * @param {string} html - HTML string to extract metadata from
 * @returns {Object} - Object with publicationDate field
 */
function harvestMetadata(html) {
    const parser = new DOMParser();
    const doc = parser.parseFromString(html, 'text/html');
    
    // Priority 1: Schema.org JSON-LD
    const ldJsonScripts = doc.querySelectorAll('script[type="application/ld+json"]');
    for (let script of ldJsonScripts) {
        try {
            const data = JSON.parse(script.textContent);
            if (data.datePublished) return { publicationDate: data.datePublished };
            if (data.publishedDate) return { publicationDate: data.publishedDate };
        } catch(e) {}
    }
    
    // Priority 2: Standard meta tags
    const metaSelectors = [
        'meta[property="article:published_time"]',
        'meta[name="date"]',
        'meta[name="publishdate"]',
        'meta[name="publication_date"]',
        'meta[property="og:published_time"]'
    ];
    
    for (let selector of metaSelectors) {
        const meta = doc.querySelector(selector);
        if (meta && meta.content) return { publicationDate: meta.content };
    }
    
    // Priority 3: time[datetime] element
    const timeEl = doc.querySelector('time[datetime]');
    if (timeEl) return { publicationDate: timeEl.getAttribute('datetime') };
    
    return { publicationDate: null };
}

// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
// SMART TAG GENERATION (5-Tag System)
// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

/**
 * Compute domain tag from source URL
 * Maps popular domains to specific tags for faster filtering
 * 
 * @param {string} sourceUrl - Source URL to compute tag from
 * @returns {string} - Domain tag (e.g., ARCHIVEX, ARCHIVEWIKI, ARCHIVEOTHER)
 */
function computeDomainTag(sourceUrl) {
    try {
        const url = new URL(sourceUrl);
        const host = url.hostname.replace('www.', '').toLowerCase();
        
        // Social media platforms
        if (host.includes('x.com') || host.includes('twitter.com')) return 'ARCHIVEX';
        if (host.includes('reddit.com')) return 'ARCHIVEREDDIT';
        if (host.includes('facebook.com')) return 'ARCHIVEFACEBOOK';
        if (host.includes('instagram.com')) return 'ARCHIVEINSTAGRAM';
        if (host.includes('linkedin.com')) return 'ARCHIVELINKEDIN';
        
        // Knowledge bases
        if (host.includes('wikipedia.org')) return 'ARCHIVEWIKI';
        if (host.includes('github.com')) return 'ARCHIVEGITHUB';
        if (host.includes('stackoverflow.com')) return 'ARCHIVESTACK';
        
        // News sites
        if (host.includes('nytimes.com') || host.includes('bbc.com') || 
            host.includes('cnn.com') || host.includes('reuters.com')) return 'ARCHIVENEWS';
        
        // Blogs & Medium
        if (host.includes('medium.com') || host.includes('substack.com')) return 'ARCHIVEBLOG';
        
        return 'ARCHIVEOTHER';
    } catch(e) {
        // Manual paste or invalid URL fallback
        return 'ARCHIVEHTML';
    }
}

/**
 * Compute length tag from word count
 * Categorizes content as SHORT, MEDIUM, or LONG
 * 
 * @param {number} wordCount - Number of words in content
 * @returns {string} - Length tag (ARCHIVESHORT, ARCHIVEMEDIUM, ARCHIVELONG)
 */
function computeLengthTag(wordCount) {
    if (wordCount < 100) return 'ARCHIVESHORT';
    if (wordCount < 1000) return 'ARCHIVEMEDIUM';
    return 'ARCHIVELONG';
}

/**
 * Compute date tag from publication date
 * Uses quarterly buckets for efficient search
 * Uses UTC to ensure deterministic tagging across timezones
 * 
 * @param {string} publicationDate - Publication date (ISO 8601 or parseable string)
 * @param {string} lastModified - Last-Modified header date
 * @returns {string} - Date tag (e.g., ARCHIVE2024Q4, ARCHIVEnow2024Q4)
 */
function computeDateTag(publicationDate, lastModified) {
    let date = null;
    let source = 'unknown';
    
    // Priority 1: Publication date from meta tags
    if (publicationDate) {
        date = new Date(publicationDate);
        source = 'pub';
    }
    // Priority 2: Last-Modified HTTP header
    else if (lastModified) {
        date = new Date(lastModified);
        source = 'mod';
    }
    // Priority 3: Current date (fallback with special marker)
    else {
        date = new Date();
        source = 'now';
    }
    
    // Validate date
    if (isNaN(date.getTime())) {
        hiveDebugWarn('âš ï¸ Invalid date, using current date as fallback');
        date = new Date();
        source = 'now';
    }
    
    // Compute quarter using UTC to ensure consistency across timezones
    const year = date.getUTCFullYear();
    const month = date.getUTCMonth() + 1; // getUTCMonth() is 0-indexed
    const quarter = Math.ceil(month / 3);
    
    // Add 'now' marker for current-date fallbacks
    const prefix = source === 'now' ? 'ARCHIVEnow' : 'ARCHIVE';
    const tag = `${prefix}${year}Q${quarter}`;
    
    hiveDebugLog(`ğŸ“… Date tag: ${tag} (source: ${source === 'pub' ? 'publication date' : source === 'mod' ? 'Last-Modified header' : 'current date'})`);
    
    return tag;
}

/**
 * Compute hash prefix tag from SHA-256 hash
 * First hex character creates 16 evenly-distributed buckets
 * 
 * @param {string} sha256Hash - SHA-256 hash string
 * @returns {string} - Hash prefix tag (ARCHIVEHASH0-F)
 */
function computeHashPrefixTag(sha256Hash) {
    if (!sha256Hash || sha256Hash.length === 0) {
        console.error('âŒ Missing SHA-256 hash for prefix tag');
        return 'ARCHIVEHASH0'; // Safe fallback
    }
    
    const firstChar = sha256Hash.charAt(0).toUpperCase();
    return `ARCHIVEHASH${firstChar}`;
}

/**
 * Generate all smart tags for optimal search performance
 * Creates 5 tags: base + domain + length + date + hash prefix
 * This enables ~1,900x faster search vs. universal tag alone
 * 
 * @param {Object} data - Object with url, wordCount, publicationDate, lastModified, hashes
 * @returns {Array<string>} - Array of 5 tags
 */
function generateArchiveTags(data) {
    // EXACTLY 5 tags for precision search (archivedcontenthaf is ALWAYS first - unique primary tag)
    const tags = [
        'archivedcontenthaf',  // 1. Primary unique tag
        computeDomainTag(data.url),  // 2. Domain (ARCHIVEX, ARCHIVEWIKI, etc.)
        computeLengthTag(data.wordCount),  // 3. Length (SHORT/MEDIUM/LONG)
        computeDateTag(data.publicationDate, data.lastModified),  // 4. Date (quarterly)
        computeHashPrefixTag(data.hashes.content.sha256)  // 5. Hash prefix (0-F)
    ];
    
    hiveDebugLog('ğŸ·ï¸ Smart tags generated (5 total):', tags);
    
    return tags;
}

// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
// HASH COMPARISON & VERIFICATION
// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

/**
 * Extract hashes from Hive post metadata
 * Parses content, title, and raw hashes from json_metadata
 * 
 * @param {Object} post - Hive post object
 * @returns {Object} - Object with content, title, and raw hashes
 */
function extractHashesFromMetadata(post) {
    try {
        let metadata = post.json_metadata;
        
        // Parse json_metadata if it's a string
        if (typeof metadata === 'string') {
            metadata = JSON.parse(metadata);
        }
        
        // Extract hashes from metadata structure
        const hashes = metadata?.hashes || {};
        
        return {
            content: {
                sha256: hashes.content?.sha256 || null,
                blake2b: hashes.content?.blake2b || null,
                md5: hashes.content?.md5 || null
            },
            title: {
                sha256: hashes.title?.sha256 || null,
                blake2b: hashes.title?.blake2b || null,
                md5: hashes.title?.md5 || null
            },
            raw: {
                sha256: hashes.raw?.sha256 || null,
                blake2b: hashes.raw?.blake2b || null,
                md5: hashes.raw?.md5 || null
            }
        };
    } catch (error) {
        console.error('âŒ Failed to extract hashes from metadata:', error);
        return {
            content: { sha256: null, blake2b: null, md5: null },
            title: { sha256: null, blake2b: null, md5: null },
            raw: { sha256: null, blake2b: null, md5: null }
        };
    }
}

/**
 * Compare current hashes with archived hashes
 * Checks if ALL 9 hashes match (content, title, raw Ã— 3 algorithms each)
 * 
 * @param {Object} currentHashes - Current hashes (content, title, raw)
 * @param {Object} archivedHashes - Archived hashes from Hive post
 * @returns {boolean} - True if ALL hashes match, false otherwise
 */
function compareHashes(currentHashes, archivedHashes) {
    // Helper to compare hash objects
    const hashesMatch = (current, archived) => {
        return current.sha256 === archived.sha256 &&
               current.blake2b === archived.blake2b &&
               current.md5 === archived.md5;
    };
    
    // Check all 9 hashes (3 types Ã— 3 algorithms)
    const contentMatch = hashesMatch(currentHashes.content, archivedHashes.content);
    const titleMatch = hashesMatch(currentHashes.title, archivedHashes.title);
    const rawMatch = hashesMatch(currentHashes.raw, archivedHashes.raw);
    
    const allMatch = contentMatch && titleMatch && rawMatch;
    
    hiveDebugLog(`ğŸ” Hash comparison:`, {
        content: contentMatch ? 'âœ… Match' : 'âŒ Differ',
        title: titleMatch ? 'âœ… Match' : 'âŒ Differ',
        raw: rawMatch ? 'âœ… Match' : 'âŒ Differ',
        overall: allMatch ? 'âœ… ALL HASHES MATCH' : 'âŒ HASHES DIFFER'
    });
    
    return allMatch;
}

// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
// EXPORTS
// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

// Export for module usage (if supported)
if (typeof module !== 'undefined' && module.exports) {
    module.exports = {
        // API Communication
        HIVE_API_NODES,
        fetchHiveAPIWithFailover,
        searchHiveByTags,
        cancelCurrentSearch,
        
        // Content Extraction & Hashing
        generateContentHash,
        extractContentFromHTML,
        countWords,
        harvestMetadata,
        
        // Smart Tag Generation
        generateArchiveTags,
        computeDomainTag,
        computeLengthTag,
        computeDateTag,
        computeHashPrefixTag,
        
        // Hash Comparison
        extractHashesFromMetadata,
        compareHashes
    };
}

// Also expose globally for direct script inclusion
if (typeof window !== 'undefined') {
    window.ArcHiveHiveLookup = {
        // API Communication
        HIVE_API_NODES,
        fetchHiveAPIWithFailover,
        searchHiveByTags,
        cancelCurrentSearch,
        
        // Content Extraction & Hashing
        generateContentHash,
        extractContentFromHTML,
        countWords,
        harvestMetadata,
        
        // Smart Tag Generation
        generateArchiveTags,
        computeDomainTag,
        computeLengthTag,
        computeDateTag,
        computeHashPrefixTag,
        
        // Hash Comparison
        extractHashesFromMetadata,
        compareHashes
    };
    
    hiveDebugLog('âœ… ArcHive Hive Lookup module loaded successfully');
    hiveDebugLog('   Available as: window.ArcHiveHiveLookup');
    hiveDebugLog('   Functions:', Object.keys(window.ArcHiveHiveLookup).length);
}
